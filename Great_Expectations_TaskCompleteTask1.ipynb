{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0KvgYslI64f"
      },
      "source": [
        "# Great Expectations Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R147FfXJG4F"
      },
      "source": [
        "## 1. Install Great Expectations Library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TGqDcWNh3Y_-"
      },
      "outputs": [],
      "source": [
        "!pip install great_expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWSO9h40JZjg"
      },
      "source": [
        "##2. Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "77qWdq8yVVEl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import great_expectations as gx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdt5KucDJu-h"
      },
      "source": [
        "##3. Load Labels.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP3MW4uUhwAR"
      },
      "source": [
        "Download and upload the [Labels.csv](https://github.com/zubxxr/SOFE3980U-Lab5/blob/main/Labels.csv) into this notebook, and then load the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogHUyzFKdS5z"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r\"C:\\Users\\12269\\Downloads\\Labels.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BCIXXwdJyS7"
      },
      "source": [
        "##4. Preview the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXpbbmRsVj0k"
      },
      "outputs": [],
      "source": [
        "df.head()\n",
        "\n",
        " Timestamp  Car1_Location_X  ...  pedestrianLocationX_BottomRight  pedestrianLocationY_BottomRight\n",
        "0  1736796157       -51.402977  ...                              610                              410\n",
        "1  1736796167       -53.819637  ...                              594                              415\n",
        "2  1736796178       -50.239144  ...                              854                              720\n",
        "3  1736796188       -53.707220  ...                              567                              425\n",
        "4  1736796198       -52.053721  ...                              537                              413\n",
        "\n",
        "[5 rows x 14 columns]\n",
        ">>>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwljyFlFJ1A8"
      },
      "source": [
        "##5. Set Up Great Expectations Context and Data Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxSmTGmZVk5U"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        "context = gx.get_context()\n",
        "data_source = context.data_sources.add_pandas(\"pandas\")\n",
        "data_asset = data_source.add_dataframe_asset(name=\"pd dataframe asset\")\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHl4W07zJ5-A"
      },
      "source": [
        "##6. Define and Create a Data Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTdpe1tVhpgp"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        "batch_definition = data_asset.add_batch_definition_whole_dataframe(\"batch definition\")\n",
        "batch = batch_definition.get_batch(batch_parameters={\"dataframe\": df})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhVlKGYXJ8Tf"
      },
      "source": [
        "##7. Define Three Expectations for Column Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ixvqF3OYnlt"
      },
      "source": [
        "Using this [link](https://greatexpectations.io/expectations/), choose three expectation functions and apply them to the labels dataset in a relevant manner.\n",
        "\n",
        "You should replace the 'ExpectColumnValuesToBeBetween' function with other functions you select from the link.\n",
        "\n",
        "You can also check the format/parameters required of each function when you click \"See more\" on the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2JMz9pScU6n"
      },
      "outputs": [],
      "source": [
        "## Original Function\n",
        "expectation = gx.expectations.ExpectColumnValuesToBeBetween(\n",
        "    column=\"column\", min_value=0, max_value=20\n",
        ")\n",
        "\n",
        "## Example Function\n",
        "\n",
        "## This function only requires a column parameter, and not a max or min value\n",
        "expectation = gx.expectations.ExpectColumnValuesToBeUnique(\n",
        "    column=\"column\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaIvn5Y-Mazw"
      },
      "source": [
        "### Expectation 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJw-qrNyhsIX"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        "ExpectColumnMinToBeBetween(\n",
        "    column=\"test\",\n",
        "    min_value=.5,\n",
        "    max_value=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaWGD8GL8jSA"
      },
      "source": [
        "### Validate Data Against Expectation 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE_iE0yr8k9y"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        ">>> validation_result = batch.validate(expectation)\n",
        "Calculating Metrics:  75%|███████████████████████████████████████████████████                 | 3/4 [00:00<00:00, 187.35it/s]\n",
        ">>> print(validation_result)\n",
        "{\n",
        "  \"success\": false,\n",
        "  \"expectation_config\": {\n",
        "    \"type\": \"expect_column_min_to_be_between\",\n",
        "    \"kwargs\": {\n",
        "      \"column\": \"test\",\n",
        "      \"min_value\": 0.5,\n",
        "      \"max_value\": 1.0,\n",
        "      \"batch_id\": \"pandas-pd dataframe asset\"\n",
        "    },\n",
        "    \"meta\": {}\n",
        "  },\n",
        "  \"result\": {},\n",
        "  \"meta\": {},\n",
        "  \"exception_info\": {\n",
        "    \"('column.min', '62ee768614516cf86253241845707c28', ())\": {\n",
        "      \"exception_traceback\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 533, in _process_direct_and_bundled_metric_computation_configurations\\n    metric_computation_configuration.metric_fn(  # type: ignore[misc] # F not callable\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\metric_provider.py\\\", line 60, in inner_func\\n    return metric_fn(*args, **kwargs)\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\column_aggregate_metric_provider.py\\\", line 77, in inner_func\\n    metric_domain_kwargs = get_dbms_compatible_metric_domain_kwargs(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\util.py\\\", line 719, in get_dbms_compatible_metric_domain_kwargs\\n    column_name: str | sqlalchemy.quoted_name = get_dbms_compatible_column_names(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\util.py\\\", line 789, in get_dbms_compatible_column_names\\n    _verify_column_names_exist_and_get_normalized_typed_column_names_map(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\util.py\\\", line 874, in _verify_column_names_exist_and_get_normalized_typed_column_names_map\\n    raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(\\ngreat_expectations.exceptions.exceptions.InvalidMetricAccessorDomainKwargsKeyError: Error: The column \\\"test\\\" in BatchData does not exist.\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\validator\\\\validation_graph.py\\\", line 276, in _resolve\\n    self._execution_engine.resolve_metrics(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 279, in resolve_metrics\\n    return self._process_direct_and_bundled_metric_computation_configurations(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 538, in _process_direct_and_bundled_metric_computation_configurations\\n    raise gx_exceptions.MetricResolutionError(\\ngreat_expectations.exceptions.exceptions.MetricResolutionError: Error: The column \\\"test\\\" in BatchData does not exist.\\n\",\n",
        "      \"exception_message\": \"Error: The column \\\"test\\\" in BatchData does not exist.\",\n",
        "      \"raised_exception\": true\n",
        "    }\n",
        "  }\n",
        "}\n",
        ">>>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37TjcPpxYiMZ"
      },
      "source": [
        "### Expectation 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duJPbIxoYfNc"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        "ExpectColumnDistinctValuesToBeInSet(\n",
        "    column=\"test\",\n",
        "    value_set=[1, 2, 3, 4, 5]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCO1JE2O8lcf"
      },
      "source": [
        "### Validate Data Against Expectation 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HbLTxQJ8rXp"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        ">>> validation_result = batch.validate(expectation)\n",
        "Calculating Metrics:  75%|███████████████████████████████████████████████████                 | 3/4 [00:00<00:00, 107.12it/s]\n",
        ">>> print(validation_result)\n",
        "{\n",
        "  \"success\": false,\n",
        "  \"expectation_config\": {\n",
        "    \"type\": \"expect_column_distinct_values_to_be_in_set\",\n",
        "    \"kwargs\": {\n",
        "      \"column\": \"test\",\n",
        "      \"value_set\": [\n",
        "        1,\n",
        "        2,\n",
        "        3,\n",
        "        4,\n",
        "        5\n",
        "      ],\n",
        "      \"batch_id\": \"pandas-pd dataframe asset\"\n",
        "    },\n",
        "    \"meta\": {}\n",
        "  },\n",
        "  \"result\": {},\n",
        "  \"meta\": {},\n",
        "  \"exception_info\": {\n",
        "    \"('column.value_counts', '62ee768614516cf86253241845707c28', '817a2a474179468a8636eb1eccaf4fdf')\": {\n",
        "      \"exception_traceback\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3653, in get_loc\\n    return self._engine.get_loc(casted_key)\\n  File \\\"pandas\\\\_libs\\\\index.pyx\\\", line 147, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"pandas\\\\_libs\\\\index.pyx\\\", line 176, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"pandas\\\\_libs\\\\hashtable_class_helper.pxi\\\", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item\\n  File \\\"pandas\\\\_libs\\\\hashtable_class_helper.pxi\\\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\\nKeyError: 'test'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 533, in _process_direct_and_bundled_metric_computation_configurations\\n    metric_computation_configuration.metric_fn(  # type: ignore[misc] # F not callable\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\metric_provider.py\\\", line 60, in inner_func\\n    return metric_fn(*args, **kwargs)\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\column_aggregate_metrics\\\\column_value_counts.py\\\", line 55, in _pandas\\n    counts: pd.Series = df[column].value_counts()\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 3761, in __getitem__\\n    indexer = self.columns.get_loc(key)\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3655, in get_loc\\n    raise KeyError(key) from err\\nKeyError: 'test'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\validator\\\\validation_graph.py\\\", line 276, in _resolve\\n    self._execution_engine.resolve_metrics(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 279, in resolve_metrics\\n    return self._process_direct_and_bundled_metric_computation_configurations(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 538, in _process_direct_and_bundled_metric_computation_configurations\\n    raise gx_exceptions.MetricResolutionError(\\ngreat_expectations.exceptions.exceptions.MetricResolutionError: 'test'\\n\",\n",
        "      \"exception_message\": \"'test'\",\n",
        "      \"raised_exception\": true\n",
        "    }\n",
        "  }\n",
        "}\n",
        ">>>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEJ28eyoYfra"
      },
      "source": [
        "### Expectation 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWFlN_hqYfkC"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        "ExpectColumnDistinctValuesToContainSet(\n",
        "    column=\"test\",\n",
        "    value_set=[1, 4]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9rzavkK8mqM"
      },
      "source": [
        "### Validate Data Against Expectation 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGed5qns8om2"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        ">>> validation_result = batch.validate(expectation)\n",
        "Calculating Metrics:  75%|███████████████████████████████████████████████████                 | 3/4 [00:00<00:00, 231.01it/s]\n",
        ">>> print(validation_result)\n",
        "{\n",
        "  \"success\": false,\n",
        "  \"expectation_config\": {\n",
        "    \"type\": \"expect_column_distinct_values_to_contain_set\",\n",
        "    \"kwargs\": {\n",
        "      \"column\": \"test\",\n",
        "      \"value_set\": [\n",
        "        1,\n",
        "        4\n",
        "      ],\n",
        "      \"batch_id\": \"pandas-pd dataframe asset\"\n",
        "    },\n",
        "    \"meta\": {}\n",
        "  },\n",
        "  \"result\": {},\n",
        "  \"meta\": {},\n",
        "  \"exception_info\": {\n",
        "    \"('column.value_counts', '62ee768614516cf86253241845707c28', '817a2a474179468a8636eb1eccaf4fdf')\": {\n",
        "      \"exception_traceback\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3653, in get_loc\\n    return self._engine.get_loc(casted_key)\\n  File \\\"pandas\\\\_libs\\\\index.pyx\\\", line 147, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"pandas\\\\_libs\\\\index.pyx\\\", line 176, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"pandas\\\\_libs\\\\hashtable_class_helper.pxi\\\", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item\\n  File \\\"pandas\\\\_libs\\\\hashtable_class_helper.pxi\\\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\\nKeyError: 'test'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 533, in _process_direct_and_bundled_metric_computation_configurations\\n    metric_computation_configuration.metric_fn(  # type: ignore[misc] # F not callable\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\metric_provider.py\\\", line 60, in inner_func\\n    return metric_fn(*args, **kwargs)\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\expectations\\\\metrics\\\\column_aggregate_metrics\\\\column_value_counts.py\\\", line 55, in _pandas\\n    counts: pd.Series = df[column].value_counts()\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 3761, in __getitem__\\n    indexer = self.columns.get_loc(key)\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3655, in get_loc\\n    raise KeyError(key) from err\\nKeyError: 'test'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\validator\\\\validation_graph.py\\\", line 276, in _resolve\\n    self._execution_engine.resolve_metrics(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 279, in resolve_metrics\\n    return self._process_direct_and_bundled_metric_computation_configurations(\\n  File \\\"C:\\\\Windows\\\\System32\\\\ge_env\\\\lib\\\\site-packages\\\\great_expectations\\\\execution_engine\\\\execution_engine.py\\\", line 538, in _process_direct_and_bundled_metric_computation_configurations\\n    raise gx_exceptions.MetricResolutionError(\\ngreat_expectations.exceptions.exceptions.MetricResolutionError: 'test'\\n\",\n",
        "      \"exception_message\": \"'test'\",\n",
        "      \"raised_exception\": true\n",
        "    }\n",
        "  }\n",
        "}\n",
        ">>>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
